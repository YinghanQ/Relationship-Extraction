{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f812c8-1d25-4b61-9fcc-df372968eb8b",
   "metadata": {},
   "source": [
    "# Attention-Based BiLSTM-CNN (Att-BiLSTM-CNN) for Relation Extraction on SemEval-2010 Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0b27f1-76aa-4cd5-a85b-e5499afbb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from config import Config\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import WordEmbeddingLoader, RelationLoader\n",
    "from model.att_blstm import Att_BLSTM\n",
    "from model.blstm import BLSTM\n",
    "from model.blstm_cnn import BLSTM_CNN\n",
    "from model.multi_att_blstm import Multi_Att_BLSTM\n",
    "from model.att_blstm_cnn import Att_BLSTM_CNN\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb9ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b4520-494e-4c10-94d4-0b7a6b03200f",
   "metadata": {},
   "source": [
    "# 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d7f2f-2027-42e7-b464-41f8506a1ee6",
   "metadata": {},
   "source": [
    "## 1.1 Raw data\n",
    "Retrieve the **sem_eval_2010_task_8** dataset from the website:  [https://huggingface.co/datasets/SemEvalWorkshop/sem_eval_2010_task_8]\n",
    "\n",
    "\n",
    " **Loading the Dataset**  \n",
    "   ```python\n",
    "   ds = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "   ```\n",
    "   - The function `load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")` fetches the **SemEval-2010 Task 8 dataset** from Hugging Face's dataset repository.\n",
    "   - This dataset is used for **relation extraction**, where the goal is to classify relationships between two entities in a sentence.\n",
    "   - The dataset typically contains:\n",
    "     - `train`: Training dataset.\n",
    "     - `test`: Test dataset.\n",
    "   - `ds` is a dictionary-like object with keys corresponding to different dataset splits (e.g., `\"train\"`, `\"test\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf87401-031f-4d82-991f-e261b67ce25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64813decf9284040b79fad889622afa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\test\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\datasets--SemEvalWorkshop--sem_eval_2010_task_8. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': ['The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.', 'The <e1>child</e1> was carefully wrapped and bound into the <e2>cradle</e2> by means of a cord.', 'The <e1>author</e1> of a keygen uses a <e2>disassembler</e2> to look at the raw assembly code.', 'A misty <e1>ridge</e1> uprises from the <e2>surge</e2>.', 'The <e1>student</e1> <e2>association</e2> is the voice of the undergraduate student population of the State University of New York at Buffalo.'], 'relation': [3, 18, 11, 18, 12]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "\n",
    "# Display the first few rows of the training set\n",
    "print(ds['train'][:5])  # This will display the first 5 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a88fe5-2015-46cd-858b-4c618782a4c2",
   "metadata": {},
   "source": [
    "## 1.2 Convert format\n",
    "The complete format conversion and data preprocessing are implemented, which converts the `.txt` file to `.json` format and splits . This is done in the `./data/Data_Preprocess.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f95b39-e429-41a2-a8b9-22162e220a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'relation': 'Component-Whole(e2,e1)', 'sentence': ['The', 'system', 'as', 'described', 'above', 'has', 'its', 'greatest', 'application', 'in', 'an', 'arrayed', '<e1>', 'configuration', '</e1>', 'of', 'antenna', '<e2>', 'elements', '</e2>', '.']}, {'id': 2, 'relation': 'Other', 'sentence': ['The', '<e1>', 'child', '</e1>', 'was', 'carefully', 'wrapped', 'and', 'bound', 'into', 'the', '<e2>', 'cradle', '</e2>', 'by', 'means', 'of', 'a', 'cord', '.']}, {'id': 3, 'relation': 'Instrument-Agency(e2,e1)', 'sentence': ['The', '<e1>', 'author', '</e1>', 'of', 'a', 'keygen', 'uses', 'a', '<e2>', 'disassembler', '</e2>', 'to', 'look', 'at', 'the', 'raw', 'assembly', 'code', '.']}, {'id': 4, 'relation': 'Other', 'sentence': ['A', 'misty', '<e1>', 'ridge', '</e1>', 'uprises', 'from', 'the', '<e2>', 'surge', '</e2>', '.']}, {'id': 5, 'relation': 'Member-Collection(e1,e2)', 'sentence': ['The', '<e1>', 'student', '</e1>', '<e2>', 'association', '</e2>', 'is', 'the', 'voice', 'of', 'the', 'undergraduate', 'student', 'population', 'of', 'the', 'State', 'University', 'of', 'New', 'York', 'at', 'Buffalo', '.']}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json_lines(file_path):\n",
    "    \"\"\"Load JSON lines data locally\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))  \n",
    "    return data\n",
    "\n",
    "# Example of loading data from a JSON file with multiple objects per line\n",
    "file_path = './data/train.json'  # Change this to your file path\n",
    "data = load_json_lines(file_path)\n",
    "\n",
    "# Print the first few records to inspect\n",
    "print(data[:5])  # Display the first two elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252bf95-5f1e-404c-9068-7c152b3ada1d",
   "metadata": {},
   "source": [
    "## 1.3 split train set and validation set\n",
    "The detailed process for splitting the dataset into training and validation sets is implemented in the script located at `./data/Data_Preprocess`. This script handles the division of the original dataset into separate training and validation subsets with a 60:40 ratio to facilitate model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c747835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8000\n",
      "Validation Set Size: 1629\n",
      "Test Set Size: 1088\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os  \n",
    "import html  \n",
    "import re  \n",
    "from collections import Counter  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from datasets import load_dataset  \n",
    "\n",
    "# Define the 19 relations for SemEval-2010 task 8\n",
    "relations = [\n",
    "    \"Cause-Effect(e1,e2)\", \"Cause-Effect(e2,e1)\",\n",
    "    \"Component-Whole(e1,e2)\", \"Component-Whole(e2,e1)\",\n",
    "    \"Content-Container(e1,e2)\", \"Content-Container(e2,e1)\",\n",
    "    \"Entity-Destination(e1,e2)\", \"Entity-Destination(e2,e1)\",\n",
    "    \"Entity-Origin(e1,e2)\", \"Entity-Origin(e2,e1)\",\n",
    "    \"Instrument-Agency(e1,e2)\", \"Instrument-Agency(e2,e1)\",\n",
    "    \"Member-Collection(e1,e2)\", \"Member-Collection(e2,e1)\",\n",
    "    \"Message-Topic(e1,e2)\", \"Message-Topic(e2,e1)\",\n",
    "    \"Product-Producer(e1,e2)\", \"Product-Producer(e2,e1)\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "# Map relations to numerical IDs and vice versa\n",
    "label2id = {label: i for i, label in enumerate(relations)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Define local file paths\n",
    "train_file = \"train.json\"  # Training set file path\n",
    "valid_file = \"validation.json\"  # Validation set file path\n",
    "test_file = \"test.json\"  # Test set file path\n",
    "\n",
    "# Load local data (single JSON object)\n",
    "def load_local_data(file_path):\n",
    "    \"\"\"Load local JSON data (single JSON object)\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Load JSON Lines format data\n",
    "def load_json_lines(file_path):\n",
    "    \"\"\"Load local JSON Lines format data\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))  \n",
    "    return data\n",
    "\n",
    "# Save data as a local JSON file (single JSON object)\n",
    "def save_local_data(data, file_path):\n",
    "    \"\"\"Save data as a JSON file (single JSON object, i.e., a list)\"\"\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Clean text data\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text data\"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return None  # Return None if the text is empty\n",
    "    text = html.unescape(text)  # Handle HTML escape characters\n",
    "    return text.strip()  # Remove leading and trailing spaces\n",
    "\n",
    "# Process e1 and e2 tags and perform tokenization\n",
    "def search_entity(sentence):\n",
    "    \"\"\"Process e1 and e2 tags and perform tokenization\"\"\"\n",
    "    e1 = re.findall(r'<e1>(.*)</e1>', sentence)[0]  # Extract the text inside e1 tags\n",
    "    e2 = re.findall(r'<e2>(.*)</e2>', sentence)[0]  # Extract the text inside e2 tags\n",
    "    # Add spaces around e1 and e2 tags and their contents\n",
    "    sentence = sentence.replace('<e1>' + e1 + '</e1>', ' <e1> ' + e1 + ' </e1> ', 1)\n",
    "    sentence = sentence.replace('<e2>' + e2 + '</e2>', ' <e2> ' + e2 + ' </e2> ', 1)\n",
    "    sentence = sentence.split()  # Tokenize the sentence by spaces\n",
    "    sentence = ' '.join(sentence)  # Join the tokenized sentence back into a string\n",
    "    # Fix any formatting issues with e1 and e2 tags\n",
    "    sentence = sentence.replace('< e1 >', '<e1>')\n",
    "    sentence = sentence.replace('< e2 >', '<e2>')\n",
    "    sentence = sentence.replace('< /e1 >', '</e1>')\n",
    "    sentence = sentence.replace('< /e2 >', '</e2>')\n",
    "    sentence = sentence.split()\n",
    "\n",
    "    # Ensure that the sentence contains e1 and e2 tags\n",
    "    assert '<e1>' in sentence\n",
    "    assert '<e2>' in sentence\n",
    "    assert '</e1>' in sentence\n",
    "    assert '</e2>' in sentence\n",
    "\n",
    "    return sentence\n",
    "\n",
    "# If local files exist, load the data\n",
    "if os.path.exists(train_file) and os.path.exists(valid_file) and os.path.exists(test_file):\n",
    "    train_data = load_local_data(train_file)\n",
    "    valid_data = load_local_data(valid_file)\n",
    "    test_data = load_local_data(test_file)\n",
    "    print(\"Data has been loaded locally!\")  # Output success message for loading data\n",
    "    print(\"Training set size:\", len(train_data))  # Output the size of the training set\n",
    "    print(\"Validation Set Size:\", len(valid_data))  # Output the size of the validation set\n",
    "    print(\"Test Set Size:\", len(test_data))  # Output the size of the test set\n",
    "else:\n",
    "    # 1. Load the dataset from Hugging Face\n",
    "    ds = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "    \n",
    "    # 2. Read the training and test data\n",
    "    train_texts_all = ds[\"train\"][\"sentence\"]  # Training set sentences\n",
    "    train_labels_all = ds[\"train\"][\"relation\"]  # Training set labels\n",
    "    test_texts = ds[\"test\"][\"sentence\"]  # Test set sentences\n",
    "    test_labels = ds[\"test\"][\"relation\"]  # Test set labels\n",
    "\n",
    "    # Add ID encoding to the training set, from 1 to 8000\n",
    "    train_data_with_ids = [{\"id\": i + 1, \"sentence\": text, \"relation\": label} \n",
    "                           for i, (text, label) in enumerate(zip(train_texts_all, train_labels_all))]\n",
    "\n",
    "    # Add ID encoding to the test set, from 8001 to 8000 + length of test set\n",
    "    test_data_with_ids = [{\"id\": i + 8001, \"sentence\": text, \"relation\": label} \n",
    "                          for i, (text, label) in enumerate(zip(test_texts, test_labels))]\n",
    "\n",
    "    # 3. Clean the data (text cleaning and splitting)\n",
    "    clean_train_data = [(clean_text(t), l) for t, l in zip(train_texts_all, train_labels_all)]\n",
    "    clean_train_data = [x for x in clean_train_data if x[0] is not None]  # Filter out empty texts\n",
    "\n",
    "    clean_test_data = [(clean_text(t), l) for t, l in zip(test_texts, test_labels)]\n",
    "    clean_test_data = [x for x in clean_test_data if x[0] is not None]  # Filter out empty texts\n",
    "\n",
    "    # 4. Split the test data into validation and test sets\n",
    "    all_test_labels = [item[1] for item in clean_test_data]\n",
    "    relation_counts = Counter(all_test_labels)  # Count the frequency of each label\n",
    "    single_instance_relations = [rel for rel, count in relation_counts.items() if count == 1]  # Single instance relations\n",
    "    single_instance_data = [item for item in clean_test_data if item[1] in single_instance_relations]  # Single instance data\n",
    "    remaining_data = [item for item in clean_test_data if item[1] not in single_instance_relations]  # Remaining data\n",
    "    remaining_labels = [x[1] for x in remaining_data]\n",
    "    # Split the remaining data into validation and test sets, preserving label proportions\n",
    "    val_data_split, test_data_split = train_test_split(\n",
    "        remaining_data,\n",
    "        test_size=0.4,  # Test set will be 40%\n",
    "        stratify=remaining_labels,  # Ensure label proportions are preserved\n",
    "        random_state=42  # Set random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    final_test_data = test_data_split + single_instance_data  # Final test set includes single instance data\n",
    "\n",
    "    # 5. Create dictionary lists (matching the previous format)\n",
    "    train_data = [{\n",
    "        \"id\": train_data_with_ids[i][\"id\"],\n",
    "        \"relation\": id2label[label],  # Use relation descriptions instead of label indices\n",
    "        \"sentence\": search_entity(text),\n",
    "        \"comment\": \"N/A\"  # Add a comment field\n",
    "    } for i, (text, label) in enumerate(clean_train_data)]\n",
    "\n",
    "    valid_data = [{\n",
    "        \"id\": test_data_with_ids[i][\"id\"],\n",
    "        \"relation\": id2label[label],  # Use relation descriptions instead of label indices\n",
    "        \"sentence\": search_entity(text),\n",
    "        \"comment\": \"N/A\"\n",
    "    } for i, (text, label) in enumerate(val_data_split)]\n",
    "\n",
    "    test_data = [{\n",
    "        \"id\": test_data_with_ids[i][\"id\"],\n",
    "        \"relation\": id2label[label],  # Use relation descriptions instead of label indices\n",
    "        \"sentence\": search_entity(text),\n",
    "        \"comment\": \"N/A\"\n",
    "    } for i, (text, label) in enumerate(final_test_data)]\n",
    "\n",
    "# Output the sizes of the datasets\n",
    "print(\"Training set size:\", len(train_data))  # Output the size of the training set\n",
    "print(\"Validation Set Size:\", len(valid_data))  # Output the size of the validation set\n",
    "print(\"Test Set Size:\", len(test_data))  # Output the size of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9fd880-0640-4b9a-9d8e-13cdb6a37d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Original Datasets distribution-----------\n",
      "Training set relation distribution:\n",
      "Instrument-Agency(e2,e1): 471\n",
      "Other: 1410\n",
      "Entity-Destination(e2,e1): 407\n",
      "Component-Whole(e1,e2): 78\n",
      "Cause-Effect(e2,e1): 659\n",
      "Content-Container(e1,e2): 844\n",
      "Product-Producer(e1,e2): 374\n",
      "Member-Collection(e1,e2): 490\n",
      "Message-Topic(e2,e1): 394\n",
      "Component-Whole(e2,e1): 612\n",
      "Entity-Origin(e1,e2): 568\n",
      "Cause-Effect(e1,e2): 344\n",
      "Instrument-Agency(e1,e2): 470\n",
      "Member-Collection(e2,e1): 144\n",
      "Message-Topic(e1,e2): 323\n",
      "Entity-Origin(e2,e1): 148\n",
      "Product-Producer(e2,e1): 166\n",
      "Entity-Destination(e1,e2): 97\n",
      "Content-Container(e2,e1): 1\n",
      "\n",
      "Test set relation distribution:\n",
      "Member-Collection(e1,e2): 210\n",
      "Message-Topic(e2,e1): 123\n",
      "Entity-Destination(e2,e1): 134\n",
      "Content-Container(e1,e2): 291\n",
      "Cause-Effect(e2,e1): 194\n",
      "Instrument-Agency(e1,e2): 162\n",
      "Message-Topic(e1,e2): 108\n",
      "Component-Whole(e2,e1): 201\n",
      "Other: 454\n",
      "Entity-Origin(e1,e2): 211\n",
      "Product-Producer(e1,e2): 153\n",
      "Entity-Origin(e2,e1): 47\n",
      "Cause-Effect(e1,e2): 134\n",
      "Instrument-Agency(e2,e1): 150\n",
      "Product-Producer(e2,e1): 39\n",
      "Entity-Destination(e1,e2): 22\n",
      "Member-Collection(e2,e1): 51\n",
      "Component-Whole(e1,e2): 32\n",
      "Content-Container(e2,e1): 1\n",
      "----------Splitted Datasets distribution-----------\n",
      "Training set relation distribution:\n",
      "Counter({'Other': 1410, 'Entity-Destination(e1,e2)': 844, 'Cause-Effect(e2,e1)': 659, 'Member-Collection(e2,e1)': 612, 'Entity-Origin(e1,e2)': 568, 'Message-Topic(e1,e2)': 490, 'Component-Whole(e2,e1)': 471, 'Component-Whole(e1,e2)': 470, 'Instrument-Agency(e2,e1)': 407, 'Product-Producer(e2,e1)': 394, 'Content-Container(e1,e2)': 374, 'Cause-Effect(e1,e2)': 344, 'Product-Producer(e1,e2)': 323, 'Content-Container(e2,e1)': 166, 'Entity-Origin(e2,e1)': 148, 'Message-Topic(e2,e1)': 144, 'Instrument-Agency(e1,e2)': 97, 'Member-Collection(e1,e2)': 78, 'Entity-Destination(e2,e1)': 1})\n",
      "\n",
      "Validation set relation distribution:\n",
      "Counter({'Other': 272, 'Entity-Destination(e1,e2)': 175, 'Entity-Origin(e1,e2)': 127, 'Message-Topic(e1,e2)': 126, 'Member-Collection(e2,e1)': 121, 'Cause-Effect(e2,e1)': 116, 'Component-Whole(e1,e2)': 97, 'Content-Container(e1,e2)': 92, 'Component-Whole(e2,e1)': 90, 'Cause-Effect(e1,e2)': 80, 'Instrument-Agency(e2,e1)': 80, 'Product-Producer(e2,e1)': 74, 'Product-Producer(e1,e2)': 65, 'Message-Topic(e2,e1)': 31, 'Entity-Origin(e2,e1)': 28, 'Content-Container(e2,e1)': 23, 'Member-Collection(e1,e2)': 19, 'Instrument-Agency(e1,e2)': 13})\n",
      "\n",
      "Test set relation distribution:\n",
      "Counter({'Other': 182, 'Entity-Destination(e1,e2)': 116, 'Entity-Origin(e1,e2)': 84, 'Message-Topic(e1,e2)': 84, 'Member-Collection(e2,e1)': 80, 'Cause-Effect(e2,e1)': 78, 'Component-Whole(e1,e2)': 65, 'Content-Container(e1,e2)': 61, 'Component-Whole(e2,e1)': 60, 'Instrument-Agency(e2,e1)': 54, 'Cause-Effect(e1,e2)': 54, 'Product-Producer(e2,e1)': 49, 'Product-Producer(e1,e2)': 43, 'Message-Topic(e2,e1)': 20, 'Entity-Origin(e2,e1)': 19, 'Content-Container(e2,e1)': 16, 'Member-Collection(e1,e2)': 13, 'Instrument-Agency(e1,e2)': 9, 'Entity-Destination(e2,e1)': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the relation labels dictionary\n",
    "relations = [\n",
    "    \"Cause-Effect(e1,e2)\",\n",
    "    \"Cause-Effect(e2,e1)\",\n",
    "    \"Instrument-Agency(e1,e2)\",\n",
    "    \"Instrument-Agency(e2,e1)\",\n",
    "    \"Product-Producer(e1,e2)\",\n",
    "    \"Product-Producer(e2,e1)\",\n",
    "    \"Content-Container(e1,e2)\",\n",
    "    \"Content-Container(e2,e1)\",\n",
    "    \"Entity-Origin(e1,e2)\",\n",
    "    \"Entity-Origin(e2,e1)\",\n",
    "    \"Entity-Destination(e1,e2)\",\n",
    "    \"Entity-Destination(e2,e1)\",\n",
    "    \"Component-Whole(e1,e2)\",\n",
    "    \"Component-Whole(e2,e1)\",\n",
    "    \"Member-Collection(e1,e2)\",\n",
    "    \"Member-Collection(e2,e1)\",\n",
    "    \"Message-Topic(e1,e2)\",\n",
    "    \"Message-Topic(e2,e1)\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(relations)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# 1. Load dataset from Hugging Face\n",
    "ds = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "\n",
    "# 2. Read training and test data\n",
    "train_texts_all = ds[\"train\"][\"sentence\"]  # Training texts\n",
    "train_labels_all = ds[\"train\"][\"relation\"]  # Training labels\n",
    "test_texts = ds[\"test\"][\"sentence\"]         # Test texts\n",
    "test_labels = ds[\"test\"][\"relation\"]        # Test labels\n",
    "\n",
    "# Get the distribution of relation labels in the training and test sets and convert to label names using id2label\n",
    "train_relation_counts = Counter([id2label[label] for label in train_labels_all])\n",
    "test_relation_counts = Counter([id2label[label] for label in test_labels])\n",
    "print(\"----------Original Datasets distribution-----------\")\n",
    "# Print relation label distribution\n",
    "print(\"Training set relation distribution:\")\n",
    "for label, count in train_relation_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"\\nTest set relation distribution:\")\n",
    "for label, count in test_relation_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"----------Splitted Datasets distribution-----------\")\n",
    "# Get the relation distribution in the training, validation, and test sets\n",
    "train_relations = [item[\"relation\"] for item in train_data]\n",
    "valid_relations = [item[\"relation\"] for item in valid_data]\n",
    "test_relations = [item[\"relation\"] for item in test_data]\n",
    "\n",
    "# Count the occurrences of each label\n",
    "train_relation_counts = Counter(train_relations)\n",
    "valid_relation_counts = Counter(valid_relations)\n",
    "test_relation_counts = Counter(test_relations)\n",
    "\n",
    "# Print the distribution results\n",
    "print(\"Training set relation distribution:\")\n",
    "print(train_relation_counts)\n",
    "\n",
    "print(\"\\nValidation set relation distribution:\")\n",
    "print(valid_relation_counts)\n",
    "\n",
    "print(\"\\nTest set relation distribution:\")\n",
    "print(test_relation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7937738-d1c2-41f3-add0-15b221ecbc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train.json: 8000 samples\n",
      "./data/validation.json: 1629 samples\n",
      "./data/test.json: 1088 samples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_local_data(file_path):\n",
    "    \"\"\"Load JSON data locally (single JSON object)\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# List of dataset files\n",
    "file_paths = [\"./data/train.json\", \"./data/validation.json\", \"./data/test.json\"]\n",
    "\n",
    "# Count the number of samples in each dataset\n",
    "for file_path in file_paths:\n",
    "    data = load_json_lines(file_path)\n",
    "    print(f\"{file_path}: {len(data)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da79882-f1ae-4d66-ae17-6722a9ae9faa",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde5ea8-cb1e-4c6f-ae14-03a9ded5b05c",
   "metadata": {},
   "source": [
    "* **<span style=\"color:red\">Att-BLSTM-CNN (Our improved model)</span>** is located in the directory `./model/att_blstm_cnn.py`.\n",
    "* **<span style=\"color:blue\">BLSTM (Baseline model)</span>** is located in the directory `./model/blstm.py`.\n",
    "* **Att_BLSTM (Comparison model)** is located in the directory `./model/att_blstm.py`.\n",
    "* **BLSTM_CNN (Comparison model)** is located in the directory `./model/blstm_cnn.py`.\n",
    "* **Multi_Att_BLSTM (Comparison model)** is located in the directory `./model/multi_att_blstm.py`.\n",
    "\n",
    "* **`run.py`**: This module is responsible for training and testing the models. It handles the main execution of the training pipeline, including model initialization, training, validation, and testing based on the provided configurations.\n",
    "\n",
    "* **`config.py`**: This module contains the default settings for various parameters used in the models. It defines configuration options such as model architecture, learning rate, batch size, and other hyperparameters that are used throughout the training and evaluation process.\n",
    "\n",
    "* **`evaluate.py`**: This module is used for evaluating the model's performance. It computes various evaluation metrics such as accuracy, precision, recall, F1-score, etc., to assess how well the trained model performs on the test dataset.\n",
    "\n",
    "* **`utils.py`**: This module is responsible for data-related operations, including reading and loading datasets, preprocessing data, and handling file operations. It provides utility functions that support data management and loading for the training and evaluation processes.\n",
    "* **Training Data CSV** will be stored in the directory `./output/<model_name>/training_data.csv`.\n",
    "* **Test Data CSV** will be stored in the directory `./output/<model_name>/test_data.csv`.\n",
    "* **Predicted Results** (in `predicted_result.txt`) will be stored in the directory `./output/<model_name>/predicted_result.txt`.\n",
    "* **Trained Model** (in `model.pkl`) will be stored in the directory `./output/<model_name>/model.pkl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125894b",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Att-BLSTM-CNN (Our improved model) Structure : </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e92bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "# @Version : Python 3.8\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Define the model class with BiLSTM, Attention, and CNN layers\n",
    "class Att_BLSTM_CNN(nn.Module):\n",
    "    def __init__(self, word_vec, class_num, config):\n",
    "        super().__init__()\n",
    "        self.word_vec = word_vec  # Pre-trained word embeddings\n",
    "        self.class_num = class_num  # Number of output classes\n",
    "\n",
    "        # Hyperparameters from the config\n",
    "        self.max_len = config.max_len  # Maximum sequence length\n",
    "        self.word_dim = config.word_dim  # Dimension of word embeddings\n",
    "        self.hidden_size = config.hidden_size  # Hidden size of LSTM\n",
    "        self.layers_num = config.layers_num  # Number of LSTM layers\n",
    "        self.emb_dropout_value = config.emb_dropout  # Dropout for embedding layer\n",
    "        self.lstm_dropout_value = config.lstm_dropout  # Dropout for LSTM layer\n",
    "        self.linear_dropout_value = config.linear_dropout  # Dropout for fully connected layer\n",
    "        self.cnn_filters = config.cnn_filters  # Number of filters in the CNN layers\n",
    "\n",
    "        # Embedding Layer: Using pre-trained word embeddings for initialization\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(\n",
    "            embeddings=self.word_vec,\n",
    "            freeze=False,  # Whether to fine-tune the word embeddings\n",
    "        )\n",
    "\n",
    "        # BiLSTM Layer: Bidirectional LSTM for sequence encoding\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.word_dim,  # Input dimension (word embedding dimension)\n",
    "            hidden_size=self.hidden_size,  # Hidden state size\n",
    "            num_layers=self.layers_num,  # Number of LSTM layers\n",
    "            bias=True,  # Whether to include bias terms\n",
    "            batch_first=True,  # Batch comes first in the input tensor\n",
    "            dropout=0,  # No dropout between LSTM layers\n",
    "            bidirectional=True,  # Bidirectional LSTM\n",
    "        )\n",
    "\n",
    "        # CNN Layer: Convolutional layers with different kernel sizes\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.hidden_size, \n",
    "                      out_channels=self.cnn_filters, \n",
    "                      kernel_size=k, \n",
    "                      padding=k // 2) for k in [2, 3, 4]  # Kernel sizes 2, 3, and 4\n",
    "        ])\n",
    "\n",
    "        # Attention Layer: To compute a weighted sum of LSTM outputs\n",
    "        self.tanh = nn.Tanh()  # Non-linear activation for attention scores\n",
    "        self.att_weight = nn.Parameter(torch.randn(1, self.hidden_size, 1))  # Attention weights\n",
    "\n",
    "        # Dropout Layers: Dropout for regularization\n",
    "        self.emb_dropout = nn.Dropout(self.emb_dropout_value)\n",
    "        self.lstm_dropout = nn.Dropout(self.lstm_dropout_value)\n",
    "        self.linear_dropout = nn.Dropout(self.linear_dropout_value)\n",
    "\n",
    "        # Fully Connected Layer: Output layer for classification\n",
    "        total_features = self.hidden_size + self.cnn_filters * len(self.convs)\n",
    "        self.dense = nn.Linear(total_features, self.class_num, bias=True)  # Final dense layer for classification\n",
    "\n",
    "        # Weight Initialization: Xavier initialization for weights\n",
    "        init.xavier_normal_(self.dense.weight)\n",
    "        init.constant_(self.dense.bias, 0.)\n",
    "\n",
    "    # LSTM Layer: Process the sequence using BiLSTM\n",
    "    def lstm_layer(self, x, mask):\n",
    "        lengths = torch.sum(mask.gt(0), dim=-1)  # Calculate sequence lengths\n",
    "        lengths = lengths.cpu()  # Ensure lengths are on CPU to avoid errors\n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)  # Pack padded sequences\n",
    "        h, (_, _) = self.lstm(x)  # Run through BiLSTM\n",
    "        h, _ = pad_packed_sequence(h, batch_first=True, padding_value=0.0, total_length=self.max_len)  # Pad sequences back\n",
    "        h = h.view(-1, self.max_len, 2, self.hidden_size)  # Reshape to include bidirectional outputs\n",
    "        h = torch.sum(h, dim=2)  # Sum bidirectional outputs (forward + backward)\n",
    "        return h\n",
    "\n",
    "    # Attention Layer: Apply attention mechanism on the BiLSTM output\n",
    "    def attention_layer(self, h, mask):\n",
    "        att_weight = self.att_weight.expand(mask.shape[0], -1, -1)  # Expand attention weight to match batch size\n",
    "        att_score = torch.bmm(self.tanh(h), att_weight)  # Compute attention scores for each timestep\n",
    "\n",
    "        # Masking to ignore padding positions\n",
    "        mask = mask.unsqueeze(dim=-1)  # Add an extra dimension to mask\n",
    "        att_score = att_score.masked_fill(mask.eq(0), float('-inf'))  # Mask padding positions with negative infinity\n",
    "        att_weight = F.softmax(att_score, dim=1)  # Apply softmax to get attention weights\n",
    "\n",
    "        # Compute attention output (context vector)\n",
    "        reps = torch.bmm(h.transpose(1, 2), att_weight).squeeze(dim=-1)  # Weighted sum of LSTM outputs\n",
    "        reps = self.tanh(reps)  # Apply Tanh activation\n",
    "        return reps\n",
    "\n",
    "    # CNN Layer: Apply convolutions with multiple kernel sizes\n",
    "    def cnn_layer(self, h):\n",
    "        h = h.permute(0, 2, 1)  # Change shape to fit Conv1D input (B, H, L)\n",
    "        cnn_outs = [F.relu(conv(h)) for conv in self.convs]  # Apply each convolution\n",
    "        # Perform global max pooling on each convolution's output\n",
    "        pooled_outs = [F.max_pool1d(cnn_out, kernel_size=cnn_out.size(2)).squeeze(2) for cnn_out in cnn_outs]\n",
    "        cnn_features = torch.cat(pooled_outs, dim=1)  # Concatenate CNN outputs from different kernels\n",
    "        return cnn_features\n",
    "\n",
    "    # Forward Pass: The complete forward pass for the model\n",
    "    def forward(self, data):\n",
    "        token = data[:, 0, :].view(-1, self.max_len)  # Extract word indices\n",
    "        mask = data[:, 1, :].view(-1, self.max_len)   # Extract mask (padding positions)\n",
    "\n",
    "        # Embedding Layer\n",
    "        emb = self.word_embedding(token)  # Convert word indices to embeddings\n",
    "        emb = self.emb_dropout(emb)  # Apply dropout to embeddings\n",
    "\n",
    "        # BiLSTM Layer\n",
    "        h = self.lstm_layer(emb, mask)  # Process through BiLSTM\n",
    "        h = self.lstm_dropout(h)  # Apply dropout to LSTM output\n",
    "\n",
    "        # Attention Representation\n",
    "        att_output = self.attention_layer(h, mask)  # Compute attention representation\n",
    "\n",
    "        # CNN Representation\n",
    "        cnn_output = self.cnn_layer(h)  # Get CNN features\n",
    "\n",
    "        # Feature Fusion: Combine Attention and CNN features\n",
    "        final_rep = torch.cat([att_output, cnn_output], dim=1)  # Concatenate features from attention and CNN layers\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        final_rep = self.linear_dropout(final_rep)  # Apply dropout\n",
    "        logits = self.dense(final_rep)  # Classify using fully connected layer\n",
    "\n",
    "        return logits  # Return the classification output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b8289-888a-4e5d-987b-579c8214055c",
   "metadata": {},
   "source": [
    "## 2.1 Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8dd3d1-5fb3-425a-b844-04c1710b4669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run.py [-h] [--data_dir DATA_DIR] [--output_dir OUTPUT_DIR]\n",
      "              [--embedding_path EMBEDDING_PATH] [--word_dim WORD_DIM]\n",
      "              [--model_name MODEL_NAME] [--mode {0,1}] [--seed SEED]\n",
      "              [--cuda CUDA] [--epoch EPOCH] [--batch_size BATCH_SIZE]\n",
      "              [--lr LR] [--max_len MAX_LEN] [--emb_dropout EMB_DROPOUT]\n",
      "              [--lstm_dropout LSTM_DROPOUT] [--linear_dropout LINEAR_DROPOUT]\n",
      "              [--hidden_size HIDDEN_SIZE] [--layers_num LAYERS_NUM]\n",
      "              [--L2_decay L2_DECAY] [--cnn_filters CNN_FILTERS]\n",
      "\n",
      "config for models\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --data_dir DATA_DIR   dir to load data\n",
      "  --output_dir OUTPUT_DIR\n",
      "                        dir to save output\n",
      "  --embedding_path EMBEDDING_PATH\n",
      "                        pre_trained word embedding\n",
      "  --word_dim WORD_DIM   dimension of word embedding\n",
      "  --model_name MODEL_NAME\n",
      "                        model name\n",
      "  --mode {0,1}          running mode: 1 for training; otherwise testing\n",
      "  --seed SEED           random seed\n",
      "  --cuda CUDA           num of gpu device, if -1, select cpu\n",
      "  --epoch EPOCH         max epoches during training\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size\n",
      "  --lr LR               learning rate\n",
      "  --max_len MAX_LEN     max length of sentence\n",
      "  --emb_dropout EMB_DROPOUT\n",
      "                        the possiblity of dropout in embedding layer\n",
      "  --lstm_dropout LSTM_DROPOUT\n",
      "                        the possiblity of dropout in (Bi)LSTM layer\n",
      "  --linear_dropout LINEAR_DROPOUT\n",
      "                        the possiblity of dropout in liner layer\n",
      "  --hidden_size HIDDEN_SIZE\n",
      "                        the dimension of hidden units in (Bi)LSTM layer\n",
      "  --layers_num LAYERS_NUM\n",
      "                        num of RNN layers\n",
      "  --L2_decay L2_DECAY   L2 weight decay\n",
      "  --cnn_filters CNN_FILTERS\n",
      "                        number of output channels for CNN layer\n"
     ]
    }
   ],
   "source": [
    "!python run.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18308e-bf19-4a11-aa5c-3ea6f3365381",
   "metadata": {},
   "source": [
    "Hereâ€™s a list of the **configurable parameters** you can adjust when running the model:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Data Directories:**\n",
    "- **`data_dir`**: The directory path to load the dataset.\n",
    "  - Default: `./data`\n",
    "  - Example: `--data_dir ./path/to/data`\n",
    "\n",
    "- **`output_dir`**: The directory path where output (like trained models) will be saved.\n",
    "  - Default: `./output`\n",
    "  - Example: `--output_dir ./path/to/output`\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Word Embedding Settings:**\n",
    "- **`embedding_path`**: The path to the pre-trained word embedding file.\n",
    "  - Default: `./embedding/glove.6B.100d.txt`\n",
    "  - Example: `--embedding_path ./embedding/custom_embeddings.txt`\n",
    "\n",
    "- **`word_dim`**: The dimensionality of the word embeddings.\n",
    "  - Default: `100`\n",
    "  - Example: `--word_dim 200`\n",
    "\n",
    "---\n",
    "\n",
    "### **3. CNN (Convolutional Neural Networks) Settings:**\n",
    "- **`cnn_filters`**: The number of output channels in the CNN layer (i.e., the number of filters).\n",
    "  - Default: `128`\n",
    "  - Example: `--cnn_filters 256`\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Model Configuration:**\n",
    "- **`model_name`**: The name of the model to use.\n",
    "  - Default: `None` (which defaults to `'Att_BLSTM_CNN'` if not specified)\n",
    "  - Example: `--model_name 'BLSTM'`\n",
    "\n",
    "- **`mode`**: Running mode. \n",
    "  - `1` for training (default)\n",
    "  - `0` for testing\n",
    "  - Example: `--mode 1`\n",
    "\n",
    "- **`seed`**: Random seed for reproducibility.\n",
    "  - Default: `5782`\n",
    "  - Example: `--seed 42`\n",
    "\n",
    "- **`cuda`**: The GPU device number to use for training (set to `-1` to use CPU).\n",
    "  - Default: `0` (first GPU)\n",
    "  - Example: `--cuda 1` (use second GPU)\n",
    "\n",
    "- **`epoch`**: The maximum number of epochs to train.\n",
    "  - Default: `20`\n",
    "  - Example: `--epoch 50`\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Hyperparameters:**\n",
    "- **`batch_size`**: The batch size used during training.\n",
    "  - Default: `10`\n",
    "  - Example: `--batch_size 32`\n",
    "\n",
    "- **`lr` (Learning Rate)**: The learning rate for the optimizer.\n",
    "  - Default: `1.0`\n",
    "  - Example: `--lr 0.001`\n",
    "\n",
    "- **`max_len`**: The maximum length of sentences or input data.\n",
    "  - Default: `100`\n",
    "  - Example: `--max_len 150`\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Dropout Settings:**\n",
    "- **`emb_dropout`**: Dropout rate in the embedding layer.\n",
    "  - Default: `0.3`\n",
    "  - Example: `--emb_dropout 0.5`\n",
    "\n",
    "- **`lstm_dropout`**: Dropout rate in the LSTM layers.\n",
    "  - Default: `0.3`\n",
    "  - Example: `--lstm_dropout 0.4`\n",
    "\n",
    "- **`linear_dropout`**: Dropout rate in the linear layer.\n",
    "  - Default: `0.5`\n",
    "  - Example: `--linear_dropout 0.6`\n",
    "\n",
    "---\n",
    "\n",
    "### **7. LSTM Settings:**\n",
    "- **`hidden_size`**: The number of hidden units in the LSTM layers.\n",
    "  - Default: `100`\n",
    "  - Example: `--hidden_size 200`\n",
    "\n",
    "- **`layers_num`**: The number of stacked LSTM layers.\n",
    "  - Default: `1`\n",
    "  - Example: `--layers_num 2`\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Regularization:**\n",
    "- **`L2_decay`**: L2 regularization weight decay.\n",
    "  - Default: `1e-5`\n",
    "  - Example: `--L2_decay 1e-4`\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Usage:**\n",
    "\n",
    "To set up and run training with customized settings:\n",
    "\n",
    "```bash\n",
    "!python run.py --model_name='Att_BLSTM_CNN' --mode=1  --output_dir='./output' --epoch=20 --batch_size=10 --lr=1 --max_len=100 --hidden_size=100 --lstm_dropout=0.3 --emb_dropout=0.5\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c5329-bfaa-4b9f-b76a-b038c71aa23b",
   "metadata": {},
   "source": [
    "## 2.2 Model Training Display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80268875-b65a-4248-b0fb-4f5b51a2cdda",
   "metadata": {},
   "source": [
    "To **train** the model, you need to set `--mode=1`. By default, in `config.py`, the mode is set to `1`, which is for **model training**.\n",
    "\n",
    "\n",
    "**Make sure you have the appropriate dataset and configurations set up before starting the training process. The default parameters are defined in `config.py`.**\n",
    "\n",
    "To run the training, use the following command:\n",
    "\n",
    "```bash\n",
    "!python run.py --model_name='Model Name' --mode=1\n",
    "```\n",
    "\n",
    "Here are the five algorithms available for training, which can be specified using the `--model_name` argument:\n",
    "\n",
    "1. **<span style=\"color:red\">Att_BLSTM_CNN (Our Improved model)</span>**: Attention-based Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "2. **BLSTM**: Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=BLSTM\n",
    "   ```\n",
    "\n",
    "3. **Att_BLSTM**: Attention-based Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM\n",
    "   ```\n",
    "\n",
    "4. **BLSTM_CNN**: Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "5. **Multi_Att_BLSTM**: Multi-Attention Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Multi_Att_BLSTM\n",
    "   ```\n",
    "Now, for model **training**, replace the `--model_name='Model Name'` with the desired model from the above list. Ensure you set `--mode=1` for training.\n",
    "\n",
    "### Model Training and Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ade1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "# @Version : Python 3.8\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from config import Config\n",
    "from utils import WordEmbeddingLoader, RelationLoader, SemEvalDataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from model.att_blstm import Att_BLSTM\n",
    "from model.blstm import BLSTM\n",
    "from model.blstm_cnn import BLSTM_CNN\n",
    "from model.multi_att_blstm import Multi_Att_BLSTM\n",
    "from model.att_blstm_cnn import Att_BLSTM_CNN\n",
    "from evaluate import Eval\n",
    "\n",
    "\n",
    "def print_result(predict_label, id2rel, start_idx=8001):\n",
    "    # Save the predicted results to a text file\n",
    "    output_path = os.path.join(config.model_dir, 'predicted_result.txt')\n",
    "    with open(output_path, 'w', encoding='utf-8') as fw:\n",
    "        for i in range(0, predict_label.shape[0]):\n",
    "            # Write each prediction with the corresponding label ID to the file\n",
    "            fw.write('{}\\t{}\\n'.format(\n",
    "                start_idx+i, id2rel[int(predict_label[i])]))\n",
    "\n",
    "\n",
    "def train(model, criterion, loader, config):\n",
    "    # Unpack training, validation (dev), and testing data loaders\n",
    "    train_loader, dev_loader, _ = loader\n",
    "    optimizer = optim.Adadelta(\n",
    "        model.parameters(), lr=config.lr, weight_decay=config.L2_decay)\n",
    "\n",
    "    # Display the model structure\n",
    "    print(model)\n",
    "    print('Training model parameters:')\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print('%s :  %s' % (name, str(param.data.shape)))\n",
    "    print('--------------------------------------')\n",
    "    print('Starting to train the model ...')\n",
    "\n",
    "    eval_tool = Eval(config)\n",
    "    max_f1 = -float('inf')\n",
    "\n",
    "    # Create directory for saving training metrics if it doesn't exist\n",
    "    csv_path = os.path.join(config.model_dir, f'{config.model_name}_train_metrics.csv')\n",
    "    if not os.path.exists(config.model_dir):\n",
    "        os.makedirs(config.model_dir)\n",
    "\n",
    "    # List to store training records\n",
    "    records = []\n",
    "\n",
    "    # Train for each epoch\n",
    "    for epoch in range(1, config.epoch + 1):\n",
    "        for step, (data, label) in enumerate(train_loader):\n",
    "            model.train()  # Set the model to training mode\n",
    "            data = data.to(config.device)  # Move data to the appropriate device (GPU/CPU)\n",
    "            label = label.to(config.device)  # Move labels to the appropriate device\n",
    "\n",
    "            optimizer.zero_grad()   # Clear gradients from previous step\n",
    "            logits = model(data)  # Forward pass\n",
    "\n",
    "            loss = criterion(logits, label)  # Calculate loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            nn.utils.clip_grad_value_(model.parameters(), clip_value=5)  # Prevent exploding gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "        # Calculate metrics for training and validation data\n",
    "        _, train_loss, _, _, _, _, _ = eval_tool.evaluate(model, criterion, train_loader)\n",
    "        f1, eval_loss, _, micro_f1, precision, recall, accuracy = eval_tool.evaluate(model, criterion, dev_loader)\n",
    "\n",
    "        # Display the metrics for this epoch\n",
    "        print(f'[{epoch:03d}] train_loss: {train_loss:.3f} | '\n",
    "              f'dev_loss: {eval_loss:.3f} | '\n",
    "              f'micro f1 on dev: {micro_f1:.4f} | '\n",
    "              f'Precision on dev: {precision:.4f} | '\n",
    "              f'Recall on dev: {recall:.4f} | '\n",
    "              f'Accuracy on dev: {accuracy:.4f} | '\n",
    "              f'Macro F1 on dev: {f1:.4f}', end=' ')\n",
    "\n",
    "        # Store metrics in the records list for later saving to CSV\n",
    "        records.append([\n",
    "            epoch, train_loss, eval_loss, micro_f1, precision, recall, accuracy, f1\n",
    "        ])\n",
    "\n",
    "        # Save the model if it achieves a better F1 score\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, 'model.pkl'))\n",
    "            print('>>> Model saved!')\n",
    "\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    # Save the training metrics to a CSV file\n",
    "    df = pd.DataFrame(records, columns=['Epoch', 'Train Loss', 'Dev Loss', 'Micro F1', 'Precision', 'Recall', 'Accuracy', 'Macro F1'])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f'Training metrics saved to {csv_path}')\n",
    "\n",
    "\n",
    "def test(model, criterion, loader, config):\n",
    "    # Start testing after training is complete\n",
    "    print('--------------------------------------')\n",
    "    print('Start testing ...')\n",
    "\n",
    "    _, _, test_loader = loader\n",
    "    model.load_state_dict(torch.load(os.path.join(config.model_dir, 'model.pkl')))  # Load the saved model\n",
    "    eval_tool = Eval(config)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    f1, test_loss, predict_label, micro_f1, precision, recall, accuracy = eval_tool.evaluate(\n",
    "        model, criterion, test_loader)\n",
    "\n",
    "    # Display the test results\n",
    "    print(f'test_loss: {test_loss:.3f} | '\n",
    "          f'Micro F1 on test: {micro_f1:.4f} | '\n",
    "          f'Precision on test: {precision:.4f} | '\n",
    "          f'Recall on test: {recall:.4f} | '\n",
    "          f'Accuracy on test: {accuracy:.4f} | '\n",
    "          f'Macro F1 on test: {f1:.4f}')\n",
    "\n",
    "    # Append test results to CSV file\n",
    "    csv_path = os.path.join(config.model_dir, f'{config.model_name}_test_metrics.csv')\n",
    "    test_record = pd.DataFrame([['Test', None, test_loss, micro_f1, precision, recall, accuracy, f1]], columns=['Epoch', 'Train Loss', 'Dev Loss', 'Micro F1', 'Precision', 'Recall', 'Accuracy', 'Macro F1'])\n",
    "    test_record.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    print(f'Test metrics appended to {csv_path}')\n",
    "\n",
    "    return predict_label\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    print('--------------------------------------')\n",
    "    print('some config:')\n",
    "    config.print_config()\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print('start to load data ...')\n",
    "    # Load word embeddings and relations data\n",
    "    word2id, word_vec = WordEmbeddingLoader(config).load_embedding()\n",
    "    rel2id, id2rel, class_num = RelationLoader(config).get_relation()\n",
    "    loader = SemEvalDataLoader(rel2id, word2id, config)\n",
    "\n",
    "    # Initialize loaders for train, dev, and test datasets\n",
    "    train_loader, dev_loader = None, None\n",
    "    if config.mode == 1:  # If in training mode\n",
    "        train_loader = loader.get_train()\n",
    "        dev_loader = loader.get_dev()\n",
    "    test_loader = loader.get_test()  # Get test data loader\n",
    "    loader = [train_loader, dev_loader, test_loader]\n",
    "    print('finish!')\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    # Initialize the model based on the configuration\n",
    "    if config.model_name == 'BLSTM':\n",
    "        model = BLSTM(word_vec=word_vec, class_num=class_num, config=config)\n",
    "    elif config.model_name == 'Att_BLSTM':\n",
    "        model = Att_BLSTM(word_vec=word_vec, class_num=class_num, config=config)\n",
    "    elif config.model_name == 'BLSTM_CNN':\n",
    "        model = BLSTM_CNN(word_vec=word_vec, class_num=class_num, config=config)\n",
    "    elif config.model_name == 'Att_BLSTM_CNN':\n",
    "        model = Att_BLSTM_CNN(word_vec=word_vec, class_num=class_num, config=config)\n",
    "    elif config.model_name == 'Multi_Att_BLSTM':\n",
    "        model = Multi_Att_BLSTM(word_vec=word_vec, class_num=class_num, config=config)\n",
    "\n",
    "    # Move model to the appropriate device (GPU/CPU)\n",
    "    model = model.to(config.device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training mode\n",
    "    if config.mode == 1:\n",
    "        train(model, criterion, loader, config)\n",
    "\n",
    "    # Testing mode\n",
    "    predict_label = test(model, criterion, loader, config)\n",
    "    print_result(predict_label, id2rel)  # Save predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3498c5-6be4-4653-90ce-280d3b35f696",
   "metadata": {},
   "source": [
    "### 2.2.1 **<span style=\"color:red\">Attention-Based BiLSTM with CNN (Att-BiLSTM-CNN)(Our Improved model)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccd7e40-3867-492c-8dfb-3c618cc9e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Att_BLSTM_CNN\n",
      "mode = 1\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Att_BLSTM_CNN\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "Att_BLSTM_CNN(\n",
      "  (word_embedding): Embedding(400006, 100)\n",
      "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(100, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "    (1): Conv1d(100, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (2): Conv1d(100, 128, kernel_size=(4,), stride=(1,), padding=(2,))\n",
      "  )\n",
      "  (tanh): Tanh()\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (lstm_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=484, out_features=19, bias=True)\n",
      ")\n",
      "Training model parameters:\n",
      "att_weight :  torch.Size([1, 100, 1])\n",
      "word_embedding.weight :  torch.Size([400006, 100])\n",
      "lstm.weight_ih_l0 :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0 :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 :  torch.Size([400])\n",
      "lstm.bias_hh_l0 :  torch.Size([400])\n",
      "lstm.weight_ih_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0_reverse :  torch.Size([400])\n",
      "lstm.bias_hh_l0_reverse :  torch.Size([400])\n",
      "convs.0.weight :  torch.Size([128, 100, 2])\n",
      "convs.0.bias :  torch.Size([128])\n",
      "convs.1.weight :  torch.Size([128, 100, 3])\n",
      "convs.1.bias :  torch.Size([128])\n",
      "convs.2.weight :  torch.Size([128, 100, 4])\n",
      "convs.2.bias :  torch.Size([128])\n",
      "dense.weight :  torch.Size([19, 484])\n",
      "dense.bias :  torch.Size([19])\n",
      "--------------------------------------\n",
      "Starting to train the model ...\n",
      "[001] train_loss: 1.023 | dev_loss: 1.027 | micro f1 on dev: 0.6808 | Precision on dev: 0.6346 | Recall on dev: 0.6432 | Accuracy on dev: 0.6808 | Macro F1 on dev: 0.7214 >>> Model saved!\n",
      "[002] train_loss: 0.806 | dev_loss: 0.877 | micro f1 on dev: 0.7195 | Precision on dev: 0.7642 | Recall on dev: 0.7034 | Accuracy on dev: 0.7195 | Macro F1 on dev: 0.7638 >>> Model saved!\n",
      "[003] train_loss: 0.700 | dev_loss: 0.810 | micro f1 on dev: 0.7416 | Precision on dev: 0.7426 | Recall on dev: 0.7642 | Accuracy on dev: 0.7416 | Macro F1 on dev: 0.7874 >>> Model saved!\n",
      "[004] train_loss: 0.645 | dev_loss: 0.867 | micro f1 on dev: 0.7317 | Precision on dev: 0.7453 | Recall on dev: 0.7578 | Accuracy on dev: 0.7317 | Macro F1 on dev: 0.7791 \n",
      "[005] train_loss: 0.544 | dev_loss: 0.801 | micro f1 on dev: 0.7557 | Precision on dev: 0.7638 | Recall on dev: 0.7706 | Accuracy on dev: 0.7557 | Macro F1 on dev: 0.8004 >>> Model saved!\n",
      "[006] train_loss: 0.565 | dev_loss: 0.836 | micro f1 on dev: 0.7526 | Precision on dev: 0.7501 | Recall on dev: 0.7860 | Accuracy on dev: 0.7526 | Macro F1 on dev: 0.7956 \n",
      "[007] train_loss: 0.470 | dev_loss: 0.798 | micro f1 on dev: 0.7698 | Precision on dev: 0.7573 | Recall on dev: 0.7949 | Accuracy on dev: 0.7698 | Macro F1 on dev: 0.8045 >>> Model saved!\n",
      "[008] train_loss: 0.453 | dev_loss: 0.822 | micro f1 on dev: 0.7600 | Precision on dev: 0.7684 | Recall on dev: 0.7966 | Accuracy on dev: 0.7600 | Macro F1 on dev: 0.8064 >>> Model saved!\n",
      "[009] train_loss: 0.381 | dev_loss: 0.813 | micro f1 on dev: 0.7710 | Precision on dev: 0.7804 | Recall on dev: 0.7955 | Accuracy on dev: 0.7710 | Macro F1 on dev: 0.8131 >>> Model saved!\n",
      "[010] train_loss: 0.380 | dev_loss: 0.871 | micro f1 on dev: 0.7716 | Precision on dev: 0.7843 | Recall on dev: 0.7973 | Accuracy on dev: 0.7716 | Macro F1 on dev: 0.8144 >>> Model saved!\n",
      "[011] train_loss: 0.326 | dev_loss: 0.824 | micro f1 on dev: 0.7808 | Precision on dev: 0.7836 | Recall on dev: 0.8080 | Accuracy on dev: 0.7808 | Macro F1 on dev: 0.8237 >>> Model saved!\n",
      "[012] train_loss: 0.358 | dev_loss: 0.909 | micro f1 on dev: 0.7729 | Precision on dev: 0.7778 | Recall on dev: 0.8012 | Accuracy on dev: 0.7729 | Macro F1 on dev: 0.8177 \n",
      "[013] train_loss: 0.286 | dev_loss: 0.839 | micro f1 on dev: 0.7753 | Precision on dev: 0.7799 | Recall on dev: 0.8017 | Accuracy on dev: 0.7753 | Macro F1 on dev: 0.8166 \n",
      "[014] train_loss: 0.267 | dev_loss: 0.830 | micro f1 on dev: 0.7821 | Precision on dev: 0.7740 | Recall on dev: 0.8152 | Accuracy on dev: 0.7821 | Macro F1 on dev: 0.8215 \n",
      "[015] train_loss: 0.277 | dev_loss: 0.865 | micro f1 on dev: 0.7704 | Precision on dev: 0.7554 | Recall on dev: 0.8056 | Accuracy on dev: 0.7704 | Macro F1 on dev: 0.8121 \n",
      "[016] train_loss: 0.208 | dev_loss: 0.871 | micro f1 on dev: 0.7845 | Precision on dev: 0.8011 | Recall on dev: 0.7994 | Accuracy on dev: 0.7845 | Macro F1 on dev: 0.8250 >>> Model saved!\n",
      "[017] train_loss: 0.185 | dev_loss: 0.909 | micro f1 on dev: 0.7864 | Precision on dev: 0.7864 | Recall on dev: 0.8113 | Accuracy on dev: 0.7864 | Macro F1 on dev: 0.8212 \n",
      "[018] train_loss: 0.167 | dev_loss: 0.920 | micro f1 on dev: 0.7851 | Precision on dev: 0.7864 | Recall on dev: 0.8054 | Accuracy on dev: 0.7851 | Macro F1 on dev: 0.8265 >>> Model saved!\n",
      "[019] train_loss: 0.179 | dev_loss: 0.892 | micro f1 on dev: 0.7851 | Precision on dev: 0.7941 | Recall on dev: 0.8122 | Accuracy on dev: 0.7851 | Macro F1 on dev: 0.8230 \n",
      "[020] train_loss: 0.132 | dev_loss: 0.942 | micro f1 on dev: 0.7839 | Precision on dev: 0.7832 | Recall on dev: 0.8123 | Accuracy on dev: 0.7839 | Macro F1 on dev: 0.8203 \n",
      "Training metrics saved to ./output/Att_BLSTM_CNN/Att_BLSTM_CNN_train_metrics.csv\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.910 | Micro F1 on test: 0.7914 | Precision on test: 0.7242 | Recall on test: 0.7547 | Accuracy on test: 0.7914 | Macro F1 on test: 0.8302\n",
      "Test metrics appended to ./output/Att_BLSTM_CNN/Att_BLSTM_CNN_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Att_BLSTM_CNN --mode=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52011ce9-e473-4e8e-b3a1-48e1db9b3a24",
   "metadata": {},
   "source": [
    "### 2.2.2 <span style=\"color:blue\">Bidirectional LSTM (BLSTM) (Baseline model)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d362ce0e-1b5a-4775-910c-2936906825da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = BLSTM\n",
      "mode = 1\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "BLSTM(\n",
      "  (word_embedding): Embedding(400006, 100)\n",
      "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (lstm_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=200, out_features=19, bias=True)\n",
      ")\n",
      "Training model parameters:\n",
      "word_embedding.weight :  torch.Size([400006, 100])\n",
      "lstm.weight_ih_l0 :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0 :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 :  torch.Size([400])\n",
      "lstm.bias_hh_l0 :  torch.Size([400])\n",
      "lstm.weight_ih_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0_reverse :  torch.Size([400])\n",
      "lstm.bias_hh_l0_reverse :  torch.Size([400])\n",
      "dense.weight :  torch.Size([19, 200])\n",
      "dense.bias :  torch.Size([19])\n",
      "--------------------------------------\n",
      "Starting to train the model ...\n",
      "[001] train_loss: 2.026 | dev_loss: 2.051 | micro f1 on dev: 0.3051 | Precision on dev: 0.1960 | Recall on dev: 0.1849 | Accuracy on dev: 0.3051 | Macro F1 on dev: 0.3026 >>> Model saved!\n",
      "[002] train_loss: 1.456 | dev_loss: 1.498 | micro f1 on dev: 0.4923 | Precision on dev: 0.4053 | Recall on dev: 0.3694 | Accuracy on dev: 0.4923 | Macro F1 on dev: 0.4824 >>> Model saved!\n",
      "[003] train_loss: 1.167 | dev_loss: 1.251 | micro f1 on dev: 0.6169 | Precision on dev: 0.5621 | Recall on dev: 0.5680 | Accuracy on dev: 0.6169 | Macro F1 on dev: 0.6316 >>> Model saved!\n",
      "[004] train_loss: 0.978 | dev_loss: 1.074 | micro f1 on dev: 0.6759 | Precision on dev: 0.6149 | Recall on dev: 0.6353 | Accuracy on dev: 0.6759 | Macro F1 on dev: 0.7067 >>> Model saved!\n",
      "[005] train_loss: 0.873 | dev_loss: 1.024 | micro f1 on dev: 0.6931 | Precision on dev: 0.6324 | Recall on dev: 0.6650 | Accuracy on dev: 0.6931 | Macro F1 on dev: 0.7329 >>> Model saved!\n",
      "[006] train_loss: 0.791 | dev_loss: 0.991 | micro f1 on dev: 0.6967 | Precision on dev: 0.6657 | Recall on dev: 0.6575 | Accuracy on dev: 0.6967 | Macro F1 on dev: 0.7473 >>> Model saved!\n",
      "[007] train_loss: 0.675 | dev_loss: 0.942 | micro f1 on dev: 0.7139 | Precision on dev: 0.6985 | Recall on dev: 0.6753 | Accuracy on dev: 0.7139 | Macro F1 on dev: 0.7571 >>> Model saved!\n",
      "[008] train_loss: 0.617 | dev_loss: 0.959 | micro f1 on dev: 0.7281 | Precision on dev: 0.6999 | Recall on dev: 0.6893 | Accuracy on dev: 0.7281 | Macro F1 on dev: 0.7719 >>> Model saved!\n",
      "[009] train_loss: 0.552 | dev_loss: 0.924 | micro f1 on dev: 0.7385 | Precision on dev: 0.7105 | Recall on dev: 0.7083 | Accuracy on dev: 0.7385 | Macro F1 on dev: 0.7772 >>> Model saved!\n",
      "[010] train_loss: 0.533 | dev_loss: 0.982 | micro f1 on dev: 0.7379 | Precision on dev: 0.7233 | Recall on dev: 0.6902 | Accuracy on dev: 0.7379 | Macro F1 on dev: 0.7773 >>> Model saved!\n",
      "[011] train_loss: 0.449 | dev_loss: 0.897 | micro f1 on dev: 0.7514 | Precision on dev: 0.7245 | Recall on dev: 0.7351 | Accuracy on dev: 0.7514 | Macro F1 on dev: 0.7897 >>> Model saved!\n",
      "[012] train_loss: 0.397 | dev_loss: 0.938 | micro f1 on dev: 0.7483 | Precision on dev: 0.7304 | Recall on dev: 0.7122 | Accuracy on dev: 0.7483 | Macro F1 on dev: 0.7824 \n",
      "[013] train_loss: 0.369 | dev_loss: 0.939 | micro f1 on dev: 0.7465 | Precision on dev: 0.7878 | Recall on dev: 0.7147 | Accuracy on dev: 0.7465 | Macro F1 on dev: 0.7878 \n",
      "[014] train_loss: 0.348 | dev_loss: 0.965 | micro f1 on dev: 0.7606 | Precision on dev: 0.7668 | Recall on dev: 0.7643 | Accuracy on dev: 0.7606 | Macro F1 on dev: 0.7984 >>> Model saved!\n",
      "[015] train_loss: 0.306 | dev_loss: 0.957 | micro f1 on dev: 0.7489 | Precision on dev: 0.7778 | Recall on dev: 0.7413 | Accuracy on dev: 0.7489 | Macro F1 on dev: 0.7925 \n",
      "[016] train_loss: 0.308 | dev_loss: 0.983 | micro f1 on dev: 0.7575 | Precision on dev: 0.7632 | Recall on dev: 0.7757 | Accuracy on dev: 0.7575 | Macro F1 on dev: 0.7996 >>> Model saved!\n",
      "[017] train_loss: 0.257 | dev_loss: 1.017 | micro f1 on dev: 0.7618 | Precision on dev: 0.7650 | Recall on dev: 0.7703 | Accuracy on dev: 0.7618 | Macro F1 on dev: 0.8028 >>> Model saved!\n",
      "[018] train_loss: 0.223 | dev_loss: 1.075 | micro f1 on dev: 0.7594 | Precision on dev: 0.7627 | Recall on dev: 0.7612 | Accuracy on dev: 0.7594 | Macro F1 on dev: 0.7977 \n",
      "[019] train_loss: 0.276 | dev_loss: 1.242 | micro f1 on dev: 0.7618 | Precision on dev: 0.7697 | Recall on dev: 0.7684 | Accuracy on dev: 0.7618 | Macro F1 on dev: 0.8037 >>> Model saved!\n",
      "[020] train_loss: 0.187 | dev_loss: 1.093 | micro f1 on dev: 0.7735 | Precision on dev: 0.7941 | Recall on dev: 0.7625 | Accuracy on dev: 0.7735 | Macro F1 on dev: 0.8064 >>> Model saved!\n",
      "Training metrics saved to ./output/BLSTM/BLSTM_train_metrics.csv\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 1.036 | Micro F1 on test: 0.7757 | Precision on test: 0.7335 | Recall on test: 0.7080 | Accuracy on test: 0.7757 | Macro F1 on test: 0.8188\n",
      "Test metrics appended to ./output/BLSTM/BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=BLSTM --mode=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbdcb7-a199-4056-a23f-576a9bb2ac29",
   "metadata": {},
   "source": [
    "### 2.2.3 Attention-based Bidirectional LSTM (Att_BLSTM) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9abf7b-e390-43cf-9cb5-7160bfde5465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Att_BLSTM\n",
      "mode = 1\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Att_BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "Att_BLSTM(\n",
      "  (word_embedding): Embedding(400006, 100)\n",
      "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (tanh): Tanh()\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (lstm_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=100, out_features=19, bias=True)\n",
      ")\n",
      "Training model parameters:\n",
      "att_weight :  torch.Size([1, 100, 1])\n",
      "word_embedding.weight :  torch.Size([400006, 100])\n",
      "lstm.weight_ih_l0 :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0 :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 :  torch.Size([400])\n",
      "lstm.bias_hh_l0 :  torch.Size([400])\n",
      "lstm.weight_ih_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0_reverse :  torch.Size([400])\n",
      "lstm.bias_hh_l0_reverse :  torch.Size([400])\n",
      "dense.weight :  torch.Size([19, 100])\n",
      "dense.bias :  torch.Size([19])\n",
      "--------------------------------------\n",
      "Starting to train the model ...\n",
      "[001] train_loss: 1.180 | dev_loss: 1.176 | micro f1 on dev: 0.6378 | Precision on dev: 0.5673 | Recall on dev: 0.5814 | Accuracy on dev: 0.6378 | Macro F1 on dev: 0.6863 >>> Model saved!\n",
      "[002] train_loss: 0.935 | dev_loss: 1.004 | micro f1 on dev: 0.6857 | Precision on dev: 0.6599 | Recall on dev: 0.6445 | Accuracy on dev: 0.6857 | Macro F1 on dev: 0.7316 >>> Model saved!\n",
      "[003] train_loss: 0.784 | dev_loss: 0.870 | micro f1 on dev: 0.7268 | Precision on dev: 0.7309 | Recall on dev: 0.6866 | Accuracy on dev: 0.7268 | Macro F1 on dev: 0.7691 >>> Model saved!\n",
      "[004] train_loss: 0.713 | dev_loss: 0.869 | micro f1 on dev: 0.7348 | Precision on dev: 0.7435 | Recall on dev: 0.7004 | Accuracy on dev: 0.7348 | Macro F1 on dev: 0.7752 >>> Model saved!\n",
      "[005] train_loss: 0.632 | dev_loss: 0.829 | micro f1 on dev: 0.7446 | Precision on dev: 0.7408 | Recall on dev: 0.7031 | Accuracy on dev: 0.7446 | Macro F1 on dev: 0.7791 >>> Model saved!\n",
      "[006] train_loss: 0.579 | dev_loss: 0.808 | micro f1 on dev: 0.7630 | Precision on dev: 0.7973 | Recall on dev: 0.7587 | Accuracy on dev: 0.7630 | Macro F1 on dev: 0.7993 >>> Model saved!\n",
      "[007] train_loss: 0.551 | dev_loss: 0.824 | micro f1 on dev: 0.7538 | Precision on dev: 0.7880 | Recall on dev: 0.7654 | Accuracy on dev: 0.7538 | Macro F1 on dev: 0.7945 \n",
      "[008] train_loss: 0.483 | dev_loss: 0.781 | micro f1 on dev: 0.7594 | Precision on dev: 0.7918 | Recall on dev: 0.7639 | Accuracy on dev: 0.7594 | Macro F1 on dev: 0.8012 >>> Model saved!\n",
      "[009] train_loss: 0.459 | dev_loss: 0.800 | micro f1 on dev: 0.7526 | Precision on dev: 0.7809 | Recall on dev: 0.7491 | Accuracy on dev: 0.7526 | Macro F1 on dev: 0.7953 \n",
      "[010] train_loss: 0.405 | dev_loss: 0.779 | micro f1 on dev: 0.7710 | Precision on dev: 0.8054 | Recall on dev: 0.7633 | Accuracy on dev: 0.7710 | Macro F1 on dev: 0.8095 >>> Model saved!\n",
      "[011] train_loss: 0.389 | dev_loss: 0.789 | micro f1 on dev: 0.7710 | Precision on dev: 0.7758 | Recall on dev: 0.7916 | Accuracy on dev: 0.7710 | Macro F1 on dev: 0.8110 >>> Model saved!\n",
      "[012] train_loss: 0.353 | dev_loss: 0.818 | micro f1 on dev: 0.7686 | Precision on dev: 0.7837 | Recall on dev: 0.7645 | Accuracy on dev: 0.7686 | Macro F1 on dev: 0.8036 \n",
      "[013] train_loss: 0.323 | dev_loss: 0.791 | micro f1 on dev: 0.7851 | Precision on dev: 0.7879 | Recall on dev: 0.7829 | Accuracy on dev: 0.7851 | Macro F1 on dev: 0.8212 >>> Model saved!\n",
      "[014] train_loss: 0.274 | dev_loss: 0.799 | micro f1 on dev: 0.7802 | Precision on dev: 0.7973 | Recall on dev: 0.7734 | Accuracy on dev: 0.7802 | Macro F1 on dev: 0.8204 \n",
      "[015] train_loss: 0.251 | dev_loss: 0.808 | micro f1 on dev: 0.7808 | Precision on dev: 0.7940 | Recall on dev: 0.7797 | Accuracy on dev: 0.7808 | Macro F1 on dev: 0.8188 \n",
      "[016] train_loss: 0.241 | dev_loss: 0.826 | micro f1 on dev: 0.7729 | Precision on dev: 0.7795 | Recall on dev: 0.7861 | Accuracy on dev: 0.7729 | Macro F1 on dev: 0.8136 \n",
      "[017] train_loss: 0.214 | dev_loss: 0.825 | micro f1 on dev: 0.7808 | Precision on dev: 0.7951 | Recall on dev: 0.7867 | Accuracy on dev: 0.7808 | Macro F1 on dev: 0.8206 \n",
      "[018] train_loss: 0.190 | dev_loss: 0.828 | micro f1 on dev: 0.7839 | Precision on dev: 0.7960 | Recall on dev: 0.7985 | Accuracy on dev: 0.7839 | Macro F1 on dev: 0.8255 >>> Model saved!\n",
      "[019] train_loss: 0.156 | dev_loss: 0.841 | micro f1 on dev: 0.7778 | Precision on dev: 0.7780 | Recall on dev: 0.7801 | Accuracy on dev: 0.7778 | Macro F1 on dev: 0.8164 \n",
      "[020] train_loss: 0.138 | dev_loss: 0.805 | micro f1 on dev: 0.7888 | Precision on dev: 0.7914 | Recall on dev: 0.8102 | Accuracy on dev: 0.7888 | Macro F1 on dev: 0.8312 >>> Model saved!\n",
      "Training metrics saved to ./output/Att_BLSTM/Att_BLSTM_train_metrics.csv\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.870 | Micro F1 on test: 0.7803 | Precision on test: 0.7342 | Recall on test: 0.7333 | Accuracy on test: 0.7803 | Macro F1 on test: 0.8222\n",
      "Test metrics appended to ./output/Att_BLSTM/Att_BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Att_BLSTM --mode=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca76cd-8051-40d9-9d41-73cba9992ae8",
   "metadata": {},
   "source": [
    "### 2.2.4 Bidirectional LSTM with Convolutional Neural Networks (BLSTM_CNN) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbef8f8-e80d-4bf5-8481-09e96c5fbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = BLSTM_CNN\n",
      "mode = 1\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/BLSTM_CNN\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "BLSTM_CNN(\n",
      "  (word_embedding): Embedding(400006, 100)\n",
      "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (conv1): Conv1d(200, 100, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(200, 100, kernel_size=(4,), stride=(1,))\n",
      "  (conv3): Conv1d(200, 100, kernel_size=(5,), stride=(1,))\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (lstm_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=300, out_features=19, bias=True)\n",
      ")\n",
      "Training model parameters:\n",
      "word_embedding.weight :  torch.Size([400006, 100])\n",
      "lstm.weight_ih_l0 :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0 :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 :  torch.Size([400])\n",
      "lstm.bias_hh_l0 :  torch.Size([400])\n",
      "lstm.weight_ih_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0_reverse :  torch.Size([400])\n",
      "lstm.bias_hh_l0_reverse :  torch.Size([400])\n",
      "conv1.weight :  torch.Size([100, 200, 3])\n",
      "conv1.bias :  torch.Size([100])\n",
      "conv2.weight :  torch.Size([100, 200, 4])\n",
      "conv2.bias :  torch.Size([100])\n",
      "conv3.weight :  torch.Size([100, 200, 5])\n",
      "conv3.bias :  torch.Size([100])\n",
      "dense.weight :  torch.Size([19, 300])\n",
      "dense.bias :  torch.Size([19])\n",
      "--------------------------------------\n",
      "Starting to train the model ...\n",
      "[001] train_loss: 1.026 | dev_loss: 1.049 | micro f1 on dev: 0.6746 | Precision on dev: 0.6219 | Recall on dev: 0.6395 | Accuracy on dev: 0.6746 | Macro F1 on dev: 0.7153 >>> Model saved!\n",
      "[002] train_loss: 0.809 | dev_loss: 0.896 | micro f1 on dev: 0.7103 | Precision on dev: 0.6658 | Recall on dev: 0.6816 | Accuracy on dev: 0.7103 | Macro F1 on dev: 0.7548 >>> Model saved!\n",
      "[003] train_loss: 0.718 | dev_loss: 0.868 | micro f1 on dev: 0.7416 | Precision on dev: 0.7633 | Recall on dev: 0.7552 | Accuracy on dev: 0.7416 | Macro F1 on dev: 0.7885 >>> Model saved!\n",
      "[004] train_loss: 0.580 | dev_loss: 0.816 | micro f1 on dev: 0.7471 | Precision on dev: 0.7939 | Recall on dev: 0.7055 | Accuracy on dev: 0.7471 | Macro F1 on dev: 0.7860 \n",
      "[005] train_loss: 0.548 | dev_loss: 0.791 | micro f1 on dev: 0.7600 | Precision on dev: 0.7680 | Recall on dev: 0.7832 | Accuracy on dev: 0.7600 | Macro F1 on dev: 0.8024 >>> Model saved!\n",
      "[006] train_loss: 0.496 | dev_loss: 0.795 | micro f1 on dev: 0.7532 | Precision on dev: 0.7682 | Recall on dev: 0.7718 | Accuracy on dev: 0.7532 | Macro F1 on dev: 0.8003 \n",
      "[007] train_loss: 0.463 | dev_loss: 0.805 | micro f1 on dev: 0.7673 | Precision on dev: 0.7560 | Recall on dev: 0.7920 | Accuracy on dev: 0.7673 | Macro F1 on dev: 0.8096 >>> Model saved!\n",
      "[008] train_loss: 0.396 | dev_loss: 0.738 | micro f1 on dev: 0.7821 | Precision on dev: 0.7834 | Recall on dev: 0.8024 | Accuracy on dev: 0.7821 | Macro F1 on dev: 0.8241 >>> Model saved!\n",
      "[009] train_loss: 0.368 | dev_loss: 0.753 | micro f1 on dev: 0.7759 | Precision on dev: 0.7757 | Recall on dev: 0.7962 | Accuracy on dev: 0.7759 | Macro F1 on dev: 0.8189 \n",
      "[010] train_loss: 0.357 | dev_loss: 0.791 | micro f1 on dev: 0.7729 | Precision on dev: 0.7700 | Recall on dev: 0.8015 | Accuracy on dev: 0.7729 | Macro F1 on dev: 0.8147 \n",
      "[011] train_loss: 0.345 | dev_loss: 0.812 | micro f1 on dev: 0.7729 | Precision on dev: 0.7762 | Recall on dev: 0.7985 | Accuracy on dev: 0.7729 | Macro F1 on dev: 0.8151 \n",
      "[012] train_loss: 0.300 | dev_loss: 0.770 | micro f1 on dev: 0.7815 | Precision on dev: 0.7748 | Recall on dev: 0.7964 | Accuracy on dev: 0.7815 | Macro F1 on dev: 0.8236 \n",
      "[013] train_loss: 0.279 | dev_loss: 0.829 | micro f1 on dev: 0.7858 | Precision on dev: 0.7818 | Recall on dev: 0.8052 | Accuracy on dev: 0.7858 | Macro F1 on dev: 0.8264 >>> Model saved!\n",
      "[014] train_loss: 0.238 | dev_loss: 0.849 | micro f1 on dev: 0.7821 | Precision on dev: 0.7865 | Recall on dev: 0.7978 | Accuracy on dev: 0.7821 | Macro F1 on dev: 0.8239 \n",
      "[015] train_loss: 0.231 | dev_loss: 0.848 | micro f1 on dev: 0.7833 | Precision on dev: 0.7910 | Recall on dev: 0.8031 | Accuracy on dev: 0.7833 | Macro F1 on dev: 0.8227 \n",
      "[016] train_loss: 0.206 | dev_loss: 0.856 | micro f1 on dev: 0.7888 | Precision on dev: 0.7860 | Recall on dev: 0.8072 | Accuracy on dev: 0.7888 | Macro F1 on dev: 0.8274 >>> Model saved!\n",
      "[017] train_loss: 0.213 | dev_loss: 0.907 | micro f1 on dev: 0.7704 | Precision on dev: 0.7605 | Recall on dev: 0.7939 | Accuracy on dev: 0.7704 | Macro F1 on dev: 0.8093 \n",
      "[018] train_loss: 0.179 | dev_loss: 0.826 | micro f1 on dev: 0.7766 | Precision on dev: 0.7806 | Recall on dev: 0.7930 | Accuracy on dev: 0.7766 | Macro F1 on dev: 0.8186 \n",
      "[019] train_loss: 0.163 | dev_loss: 0.986 | micro f1 on dev: 0.7827 | Precision on dev: 0.7846 | Recall on dev: 0.8077 | Accuracy on dev: 0.7827 | Macro F1 on dev: 0.8289 >>> Model saved!\n",
      "[020] train_loss: 0.151 | dev_loss: 0.940 | micro f1 on dev: 0.7759 | Precision on dev: 0.7796 | Recall on dev: 0.7996 | Accuracy on dev: 0.7759 | Macro F1 on dev: 0.8172 \n",
      "Training metrics saved to ./output/BLSTM_CNN/BLSTM_CNN_train_metrics.csv\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.977 | Micro F1 on test: 0.7895 | Precision on test: 0.7222 | Recall on test: 0.7566 | Accuracy on test: 0.7895 | Macro F1 on test: 0.8287\n",
      "Test metrics appended to ./output/BLSTM_CNN/BLSTM_CNN_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=BLSTM_CNN --mode=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5cc2a-f53a-4820-a70d-14ccff2d02ca",
   "metadata": {},
   "source": [
    "### 2.2.5 Multi-Attention Bidirectional LSTM (Multi_Att_BLSTM) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b18b11-acf5-40ed-80ef-0cc1147afd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Multi_Att_BLSTM\n",
      "mode = 1\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Multi_Att_BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "Multi_Att_BLSTM(\n",
      "  (tanh): Tanh()\n",
      "  (word_embedding): Embedding(400006, 100)\n",
      "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (self_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (lstm_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=100, out_features=19, bias=True)\n",
      ")\n",
      "Training model parameters:\n",
      "word_embedding.weight :  torch.Size([400006, 100])\n",
      "lstm.weight_ih_l0 :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0 :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 :  torch.Size([400])\n",
      "lstm.bias_hh_l0 :  torch.Size([400])\n",
      "lstm.weight_ih_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.weight_hh_l0_reverse :  torch.Size([400, 100])\n",
      "lstm.bias_ih_l0_reverse :  torch.Size([400])\n",
      "lstm.bias_hh_l0_reverse :  torch.Size([400])\n",
      "self_attention.in_proj_weight :  torch.Size([300, 100])\n",
      "self_attention.in_proj_bias :  torch.Size([300])\n",
      "self_attention.out_proj.weight :  torch.Size([100, 100])\n",
      "self_attention.out_proj.bias :  torch.Size([100])\n",
      "dense.weight :  torch.Size([19, 100])\n",
      "dense.bias :  torch.Size([19])\n",
      "--------------------------------------\n",
      "Starting to train the model ...\n",
      "[001] train_loss: 1.385 | dev_loss: 1.396 | micro f1 on dev: 0.5506 | Precision on dev: 0.4931 | Recall on dev: 0.4835 | Accuracy on dev: 0.5506 | Macro F1 on dev: 0.5810 >>> Model saved!\n",
      "[002] train_loss: 1.046 | dev_loss: 1.062 | micro f1 on dev: 0.6636 | Precision on dev: 0.6401 | Recall on dev: 0.6055 | Accuracy on dev: 0.6636 | Macro F1 on dev: 0.6941 >>> Model saved!\n",
      "[003] train_loss: 0.801 | dev_loss: 0.907 | micro f1 on dev: 0.7158 | Precision on dev: 0.7074 | Recall on dev: 0.6862 | Accuracy on dev: 0.7158 | Macro F1 on dev: 0.7600 >>> Model saved!\n",
      "[004] train_loss: 0.727 | dev_loss: 0.896 | micro f1 on dev: 0.7139 | Precision on dev: 0.6884 | Recall on dev: 0.6978 | Accuracy on dev: 0.7139 | Macro F1 on dev: 0.7359 \n",
      "[005] train_loss: 0.580 | dev_loss: 0.808 | micro f1 on dev: 0.7409 | Precision on dev: 0.7734 | Recall on dev: 0.7377 | Accuracy on dev: 0.7409 | Macro F1 on dev: 0.7850 >>> Model saved!\n",
      "[006] train_loss: 0.505 | dev_loss: 0.765 | micro f1 on dev: 0.7563 | Precision on dev: 0.8025 | Recall on dev: 0.7401 | Accuracy on dev: 0.7563 | Macro F1 on dev: 0.7987 >>> Model saved!\n",
      "[007] train_loss: 0.472 | dev_loss: 0.770 | micro f1 on dev: 0.7624 | Precision on dev: 0.7635 | Recall on dev: 0.7882 | Accuracy on dev: 0.7624 | Macro F1 on dev: 0.8051 >>> Model saved!\n",
      "[008] train_loss: 0.411 | dev_loss: 0.778 | micro f1 on dev: 0.7686 | Precision on dev: 0.7774 | Recall on dev: 0.7929 | Accuracy on dev: 0.7686 | Macro F1 on dev: 0.8052 >>> Model saved!\n",
      "[009] train_loss: 0.361 | dev_loss: 0.782 | micro f1 on dev: 0.7710 | Precision on dev: 0.7680 | Recall on dev: 0.7888 | Accuracy on dev: 0.7710 | Macro F1 on dev: 0.8067 >>> Model saved!\n",
      "[010] train_loss: 0.310 | dev_loss: 0.770 | micro f1 on dev: 0.7753 | Precision on dev: 0.7800 | Recall on dev: 0.7838 | Accuracy on dev: 0.7753 | Macro F1 on dev: 0.8170 >>> Model saved!\n",
      "[011] train_loss: 0.274 | dev_loss: 0.816 | micro f1 on dev: 0.7741 | Precision on dev: 0.7786 | Recall on dev: 0.7865 | Accuracy on dev: 0.7741 | Macro F1 on dev: 0.8117 \n",
      "[012] train_loss: 0.253 | dev_loss: 0.855 | micro f1 on dev: 0.7753 | Precision on dev: 0.7749 | Recall on dev: 0.7930 | Accuracy on dev: 0.7753 | Macro F1 on dev: 0.8151 \n",
      "[013] train_loss: 0.209 | dev_loss: 0.832 | micro f1 on dev: 0.7723 | Precision on dev: 0.7831 | Recall on dev: 0.7713 | Accuracy on dev: 0.7723 | Macro F1 on dev: 0.8123 \n",
      "[014] train_loss: 0.162 | dev_loss: 0.845 | micro f1 on dev: 0.7839 | Precision on dev: 0.7909 | Recall on dev: 0.7936 | Accuracy on dev: 0.7839 | Macro F1 on dev: 0.8212 >>> Model saved!\n",
      "[015] train_loss: 0.139 | dev_loss: 0.862 | micro f1 on dev: 0.7729 | Precision on dev: 0.7857 | Recall on dev: 0.7759 | Accuracy on dev: 0.7729 | Macro F1 on dev: 0.8146 \n",
      "[016] train_loss: 0.178 | dev_loss: 0.927 | micro f1 on dev: 0.7704 | Precision on dev: 0.7593 | Recall on dev: 0.7965 | Accuracy on dev: 0.7704 | Macro F1 on dev: 0.8121 \n",
      "[017] train_loss: 0.117 | dev_loss: 0.876 | micro f1 on dev: 0.7894 | Precision on dev: 0.7933 | Recall on dev: 0.8056 | Accuracy on dev: 0.7894 | Macro F1 on dev: 0.8253 >>> Model saved!\n",
      "[018] train_loss: 0.098 | dev_loss: 0.942 | micro f1 on dev: 0.7882 | Precision on dev: 0.7891 | Recall on dev: 0.7868 | Accuracy on dev: 0.7882 | Macro F1 on dev: 0.8203 \n",
      "[019] train_loss: 0.076 | dev_loss: 0.953 | micro f1 on dev: 0.7851 | Precision on dev: 0.7903 | Recall on dev: 0.7896 | Accuracy on dev: 0.7851 | Macro F1 on dev: 0.8222 \n",
      "[020] train_loss: 0.084 | dev_loss: 0.948 | micro f1 on dev: 0.7876 | Precision on dev: 0.7942 | Recall on dev: 0.8059 | Accuracy on dev: 0.7876 | Macro F1 on dev: 0.8226 \n",
      "Training metrics saved to ./output/Multi_Att_BLSTM/Multi_Att_BLSTM_train_metrics.csv\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.953 | Micro F1 on test: 0.7757 | Precision on test: 0.7188 | Recall on test: 0.7354 | Accuracy on test: 0.7757 | Macro F1 on test: 0.8189\n",
      "Test metrics appended to ./output/Multi_Att_BLSTM/Multi_Att_BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Multi_Att_BLSTM --mode=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a910368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae2a25cb-2ece-4d29-89cf-f203dc2275df",
   "metadata": {},
   "source": [
    "# 3. Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a258fae-c184-421e-a5d1-fa7cb610d13b",
   "metadata": {},
   "source": [
    "To test the model's performance, you need to set `--mode=0`. By default, in `config.py`, the mode is set to `1`, which is for model training.\n",
    "\n",
    "**Before testing the model, make sure that the trained model is available in the appropriate directory.**\n",
    "\n",
    "To run the test, use the following command:\n",
    "\n",
    "```bash\n",
    "!python run.py --model_name='Model Name' --mode=0\n",
    "``` \n",
    "\n",
    "\n",
    "Here are the five algorithms available for testing, which can be specified using the `--model_name` argument:\n",
    "\n",
    "1. **<span style=\"color:red\">Att_BLSTM_CNNï¼ˆOur Improved model)</span>**: Attention-based Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "2. **BLSTM**: Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=BLSTM\n",
    "   ```\n",
    "\n",
    "3. **Att_BLSTM**: Attention-based Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM\n",
    "   ```\n",
    "\n",
    "4. **BLSTM_CNN**: Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "5. **Multi_Att_BLSTM**: Multi-Attention Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Multi_Att_BLSTM\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94fc93-e3ca-496a-a2db-e0ee25f76863",
   "metadata": {},
   "source": [
    "## 3.1 **<span style=\"color:red\">Attention-Based BiLSTM with CNN (Att-BiLSTM-CNN) (Our Improved model)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a685117-54a5-406f-a3de-6507fc22699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Att_BLSTM_CNN\n",
      "mode = 0\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Att_BLSTM_CNN\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.910 | Micro F1 on test: 0.7914 | Precision on test: 0.7242 | Recall on test: 0.7547 | Accuracy on test: 0.7914 | Macro F1 on test: 0.8302\n",
      "Test metrics appended to ./output/Att_BLSTM_CNN/Att_BLSTM_CNN_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Att_BLSTM_CNN --mode=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30410bc4-0883-4f07-8629-44854aeeb292",
   "metadata": {},
   "source": [
    "## 3.2 <span style=\"color:blue\">Bidirectional LSTM (BLSTM)(Baseline model)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9f01f2-8b52-4e24-a932-527d39f4e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = BLSTM\n",
      "mode = 0\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 1.036 | Micro F1 on test: 0.7757 | Precision on test: 0.7335 | Recall on test: 0.7080 | Accuracy on test: 0.7757 | Macro F1 on test: 0.8188\n",
      "Test metrics appended to ./output/BLSTM/BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=BLSTM --mode=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e111d-d274-4c44-b9e4-44da44a961e4",
   "metadata": {},
   "source": [
    "## 3.3 Attention-based Bidirectional LSTM (Att_BLSTM) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da92d000-c92d-489d-936a-48079000d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Att_BLSTM\n",
      "mode = 0\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Att_BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.870 | Micro F1 on test: 0.7803 | Precision on test: 0.7342 | Recall on test: 0.7333 | Accuracy on test: 0.7803 | Macro F1 on test: 0.8222\n",
      "Test metrics appended to ./output/Att_BLSTM/Att_BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Att_BLSTM --mode=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f151baf-7036-4a14-9e50-c249b49d5fc7",
   "metadata": {},
   "source": [
    "## 3.4 Bidirectional LSTM with Convolutional Neural Networks (BLSTM_CNN) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc7656f-12ee-4089-98e4-3c9164e072f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = BLSTM_CNN\n",
      "mode = 0\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/BLSTM_CNN\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.977 | Micro F1 on test: 0.7895 | Precision on test: 0.7222 | Recall on test: 0.7566 | Accuracy on test: 0.7895 | Macro F1 on test: 0.8287\n",
      "Test metrics appended to ./output/BLSTM_CNN/BLSTM_CNN_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=BLSTM_CNN --mode=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd48727-58f4-426c-8b1f-e9f8b38a5973",
   "metadata": {},
   "source": [
    "## 3.5 Multi-Attention Bidirectional LSTM (Multi_Att_BLSTM) (Comparison model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f806df-88a9-430d-bc0c-db2525db770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "some config:\n",
      "data_dir = ./data\n",
      "output_dir = ./output\n",
      "embedding_path = ./embedding/glove.6B.100d.txt\n",
      "word_dim = 100\n",
      "cnn_filters = 128\n",
      "model_name = Multi_Att_BLSTM\n",
      "mode = 0\n",
      "seed = 5782\n",
      "cuda = 0\n",
      "epoch = 20\n",
      "batch_size = 10\n",
      "lr = 1.0\n",
      "max_len = 100\n",
      "emb_dropout = 0.3\n",
      "lstm_dropout = 0.3\n",
      "linear_dropout = 0.5\n",
      "hidden_size = 100\n",
      "layers_num = 1\n",
      "L2_decay = 1e-05\n",
      "device = cuda:0\n",
      "model_dir = ./output/Multi_Att_BLSTM\n",
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Start testing ...\n",
      "test_loss: 0.953 | Micro F1 on test: 0.7757 | Precision on test: 0.7188 | Recall on test: 0.7354 | Accuracy on test: 0.7757 | Macro F1 on test: 0.8189\n",
      "Test metrics appended to ./output/Multi_Att_BLSTM/Multi_Att_BLSTM_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_name=Multi_Att_BLSTM --mode=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ae508-d613-42c2-9e92-6518fea2fa8d",
   "metadata": {},
   "source": [
    "# 4. Prediction Demo\n",
    "\n",
    "To evaluate the actual prediction ability of the trained model, we use `demo.py` to predict the relation between two entities in a single input sentence and output the result.\n",
    "\n",
    "**Before predicting the entity relation in a new sentence, make sure that the trained model is available in the appropriate directory.**\n",
    "\n",
    "To predict the relation, use the following command:\n",
    "\n",
    "```bash\n",
    "!python demo.py --model_name='Model Name'\n",
    "```\n",
    "\n",
    "If the content cannot be output in real-time due to buffering problems, you can use the following command:\n",
    "\n",
    "```bash\n",
    "%run demo.py --model_name='Model Name'\n",
    "```\n",
    "\n",
    "\n",
    "Here are the five algorithms available for predicting, which can be specified using the `--model_name` argument:\n",
    "\n",
    "1. **<span style=\"color:red\">Att_BLSTM_CNNï¼ˆOur Improved model)</span>**: Attention-based Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "2. **BLSTM**: Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=BLSTM\n",
    "   ```\n",
    "\n",
    "3. **Att_BLSTM**: Attention-based Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Att_BLSTM\n",
    "   ```\n",
    "\n",
    "4. **BLSTM_CNN**: Bidirectional LSTM with Convolutional Neural Networks\n",
    "   ```bash\n",
    "   --model_name=BLSTM_CNN\n",
    "   ```\n",
    "\n",
    "5. **Multi_Att_BLSTM**: Multi-Attention Bidirectional LSTM model\n",
    "   ```bash\n",
    "   --model_name=Multi_Att_BLSTM\n",
    "   ```\n",
    "**Some test cases are provided below, and you can choose from these examples.**\n",
    "* **Valid example:**\n",
    "1. A child is told a `<e1>lie</e1>` for several years by their `<e2>parents</e2>` before he/she realizes that a Santa Claus does not exist.\n",
    "   - **Expected Output**: `Agent-Patient(e2,e1)`\n",
    "   \n",
    "2. The disgusting scene was retaliation against her brother Philip who rents the `<e1>room</e1>` inside this apartment `<e2>house</e2>` on Lombard street.\n",
    "   - **Expected Output**: `Agent-Patient(e2,e1)`\n",
    "   \n",
    "3. This `<e1>thesis</e1>` defines the `<e2>clinical characteristics</e2>` of amyloid disease.\n",
    "   - **Expected Output**: `Agent-Theme(e1,e2)`\n",
    "   \n",
    "4. The `<e1>company</e1>` fabricates plastic `<e2>chairs</e2>`.\n",
    "   - **Expected Output**: `Agent-Patient(e1,e2)`\n",
    "\n",
    "* **InValid example:**\n",
    "The school `<e1>master</e1>` teaches the lesson with a `<e2>stick</e2>`.\n",
    "   - **Expected Output**: `Instrument-Agency(e2,e1)`\n",
    "   - **Error**: *\"The sentence structure does not align with the typical agent-patient or theme roles; the expected output should be Instrument-Agency(e2,e1).\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e19de-8357-46fa-9be9-95fa0a804243",
   "metadata": {},
   "source": [
    "## 4.1 **<span style=\"color:red\">Attention-Based BiLSTM with CNN (Att-BiLSTM-CNN) (Our Improved model)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7166543-501a-4d5f-80bc-5508ad00768e",
   "metadata": {},
   "source": [
    "### Valid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c78ae0-3c1f-4c68-8fe8-1ac57aa4261e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n",
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n",
      "Exiting the program. Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name Att_BLSTM_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376a3f-c9d2-4a36-a862-d543cf50e979",
   "metadata": {},
   "source": [
    "### invalid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3069c9d-d0ce-4b8c-aa0b-f1be1f1e7664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Starting data loading process...\n",
      "Data loading complete!\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Please enter a sentence containing <e1> and <e2> tags (type 'break' to exit) **********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence:  The school <e1>master</e1> teaches the lesson with a <e2>stick<e2>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input format error. Please ensure the sentence contains both <e1> and <e2> tags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Please enter a sentence containing <e1> and <e2> tags (type 'break' to exit) **********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence:  break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = master, e2 = stick\n",
      "Predicted relation: Instrument-Agency(e2,e1)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name Att_BLSTM_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21a6fc-e7dd-4bd6-828c-75f42d5666dc",
   "metadata": {},
   "source": [
    "## 4.2 Bidirectional LSTM (BLSTM)(Baseline model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe0fdb8-adab-4a61-bcac-a81c1b0950d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n",
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n",
      "Exiting the program. Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name BLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedbbd1-1270-4cc0-8111-6c7522d820e4",
   "metadata": {},
   "source": [
    "## 4.3 Attention-based Bidirectional LSTM (Att_BLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ecdb5b-bb96-40f9-8496-28ce267a4bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n",
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n",
      "Exiting the program. Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The <e1>company</e1> fabricates plastic <e2>chairs</e2>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = company, e2 = chairs\n",
      "Predicted relation: Product-Producer(e2,e1)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name Att_BLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f3a00-7044-4889-ac0d-6e80d1aa97c6",
   "metadata": {},
   "source": [
    "## 4.4 Bidirectional LSTM with Convolutional Neural Networks (BLSTM_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2ca664-974e-4712-b185-93b348cf674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "start to load data ...\n",
      "finish!\n",
      "--------------------------------------\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The disgusting scene was retaliation against her brother Philip who rents the <e1>room</e1> inside this apartment <e2>house</e2> on Lombard street.\n",
      "Extracted entities: e1 = room, e2 = house\n",
      "Predicted relation: Component-Whole(e1,e2)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: This <e1>thesis</e1> defines the <e2>clinical characteristics</e2> of amyloid disease.\n",
      "Extracted entities: e1 = thesis, e2 = clinical characteristics\n",
      "Predicted relation: Message-Topic(e1,e2)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: A child is told a <e1>lie</e1> for several years by their <e2>parents</e2> before he/she realizes that a Santa Claus does not exist.\n",
      "Extracted entities: e1 = lie, e2 = parents\n",
      "Predicted relation: Product-Producer(e1,e2)\n",
      "\n",
      "\n",
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n",
      "Exiting the program. Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: The disgusting scene was retaliation against her brother Philip who rents the <e1>room</e1> inside this apartment <e2>house</e2> on Lombard street.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = room, e2 = house\n",
      "Predicted relation: Component-Whole(e1,e2)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: This <e1>thesis</e1> defines the <e2>clinical characteristics</e2> of amyloid disease.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = thesis, e2 = clinical characteristics\n",
      "Predicted relation: Message-Topic(e1,e2)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: A child is told a <e1>lie</e1> for several years by their <e2>parents</e2> before he/she realizes that a Santa Claus does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = lie, e2 = parents\n",
      "Predicted relation: Product-Producer(e1,e2)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Please enter a sentence with <e1> and <e2> tags (type 'break' to exit)**********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence: break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name BLSTM_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfcde4-514a-4511-b57f-e8d57a814fae",
   "metadata": {},
   "source": [
    "## 4.5 Multi-Attention Bidirectional LSTM (Multi_Att_BLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd429cd-adc9-474d-b9df-59f4d0504cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Starting data loading process...\n",
      "Data loading complete!\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Please enter a sentence containing <e1> and <e2> tags (type 'break' to exit) **********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence:  A child is told a <e1>lie</e1> for several years by their <e2>parents</e2> before he/she realizes that a Santa Claus does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: e1 = lie, e2 = parents\n",
      "Predicted relation: Product-Producer(e1,e2)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Please enter a sentence containing <e1> and <e2> tags (type 'break' to exit) **********\n",
      "Example: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "\n",
      "Test sentence:  break\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "%run demo.py --model_name Multi_Att_BLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3c607-8c9b-4229-a62e-b5b51955fcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
